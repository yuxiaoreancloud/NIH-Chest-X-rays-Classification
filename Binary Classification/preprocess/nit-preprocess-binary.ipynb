{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92266</th>\n",
       "      <td>00023064_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>23064</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62585</th>\n",
       "      <td>00015498_003.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>3</td>\n",
       "      <td>15498</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00000005_004.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2986</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22501</th>\n",
       "      <td>00005963_022.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>22</td>\n",
       "      <td>5963</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24379</th>\n",
       "      <td>00006411_026.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>26</td>\n",
       "      <td>6411</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49288</th>\n",
       "      <td>00012502_005.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>5</td>\n",
       "      <td>12502</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>00001620_002.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>2</td>\n",
       "      <td>1620</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90071</th>\n",
       "      <td>00022397_004.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>4</td>\n",
       "      <td>22397</td>\n",
       "      <td>0.431579</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102919</th>\n",
       "      <td>00027436_004.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>4</td>\n",
       "      <td>27436</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37964</th>\n",
       "      <td>00009983_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>9983</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
       "92266   00023064_000.png     No Finding            0       23064     0.252632   \n",
       "62585   00015498_003.png     No Finding            3       15498     0.200000   \n",
       "17      00000005_004.png     No Finding            4           5     0.736842   \n",
       "22501   00005963_022.png     No Finding           22        5963     0.231579   \n",
       "24379   00006411_026.png     No Finding           26        6411     0.747368   \n",
       "49288   00012502_005.png     No Finding            5       12502     0.315789   \n",
       "6011    00001620_002.png     No Finding            2        1620     0.442105   \n",
       "90071   00022397_004.png     No Finding            4       22397     0.431579   \n",
       "102919  00027436_004.png     No Finding            4       27436     0.200000   \n",
       "37964   00009983_000.png     No Finding            0        9983     0.484211   \n",
       "\n",
       "       Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "92266               M            PA                 3056     2544   \n",
       "62585               M            AP                 2048     2500   \n",
       "17                  F            PA                 2986     2991   \n",
       "22501               M            PA                 2048     2500   \n",
       "24379               M            PA                 2992     2991   \n",
       "49288               M            PA                 2500     2048   \n",
       "6011                M            PA                 2992     2991   \n",
       "90071               F            AP                 3056     2544   \n",
       "102919              F            PA                 2544     3056   \n",
       "37964               F            PA                 2500     2048   \n",
       "\n",
       "        OriginalImagePixelSpacing[x     y]  Unnamed: 11  tl  \n",
       "92266                         0.139  0.139          NaN   0  \n",
       "62585                         0.168  0.168          NaN   0  \n",
       "17                            0.143  0.143          NaN   0  \n",
       "22501                         0.171  0.171          NaN   0  \n",
       "24379                         0.143  0.143          NaN   0  \n",
       "49288                         0.168  0.168          NaN   0  \n",
       "6011                          0.143  0.143          NaN   0  \n",
       "90071                         0.139  0.139          NaN   0  \n",
       "102919                        0.139  0.139          NaN   0  \n",
       "37964                         0.168  0.168          NaN   0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import h5py\n",
    "\n",
    "df = pd.read_csv('Data_Entry_2017.csv')\n",
    "\n",
    "diseases = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\n",
    "# Remove rows with unreasonable ages \n",
    "df = df.drop(df.sort_values(by='Patient Age',ascending=False).head(16).index)\n",
    "df['Patient Age'] = df['Patient Age']/df['Patient Age'].max()\n",
    "\n",
    "with open('test_list.txt', 'r') as f1:\n",
    "  x = f1.read().split()\n",
    "with open('train_val_list.txt', 'r') as f2:\n",
    "  y = f2.read().split()\n",
    "\n",
    "train = df.loc[df['Image Index'].isin(y)]\n",
    "train['tl'] = train['Finding Labels'].apply(lambda a: 0 if a=='No Finding' else 1)\n",
    "train = shuffle(train)\n",
    "train_files_list = train['Image Index'].tolist()\n",
    "trainL = np.array(train['tl'].tolist(), dtype=int)\n",
    "\n",
    "test = df.loc[df['Image Index'].isin(x)]\n",
    "test['lt'] = test['Finding Labels'].apply(lambda b: 0 if b=='No Finding' else 1)\n",
    "test = shuffle(test)\n",
    "test_files_list = test['Image Index'].tolist()\n",
    "testL = np.array(test['lt'].tolist(), dtype=int)\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86512, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('./efs/Binary/train_files_list.dat', 'wb'), train_files_list, allow_pickle=False)\n",
    "np.save(open('./efs/Binary/trainL.dat', 'wb'), trainL, allow_pickle=False)\n",
    "np.save(open('./efs/Binary/test_files_list.dat', 'wb'), test_files_list, allow_pickle=False)\n",
    "np.save(open('./efs/Binary/testL.dat', 'wb'), testL, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import boto3\n",
    "import tempfile\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import ImageFile\n",
    "\n",
    "# Helper method to convert images to training tensors \n",
    "def path_to_tensor(img_path, shape):\n",
    "    s3 = boto3.resource('s3', region_name='us-east-1', \n",
    "                        aws_access_key_id = 'AKIAJR75PXKNLAFCI3UQ',\n",
    "                        aws_secret_access_key= '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')\n",
    "    bucket = s3.Bucket('nih-chest-xrays-dataset')\n",
    "    object = bucket.Object('images/' + img_path )\n",
    "    \n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    \n",
    "    with open(tmp.name, 'wb') as f:\n",
    "        object.download_fileobj(f)\n",
    "        # loads RGB image as PIL.Image.Image type\n",
    "        img = image.load_img(tmp.name, target_size=shape)\n",
    "        # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "        x = image.img_to_array(img)/255\n",
    "        # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "        return np.expand_dims(x, axis=0)\n",
    "\n",
    "# Convert images to training tensors \n",
    "def paths_to_tensor(img_paths, shape):\n",
    "    list_of_tensors = [path_to_tensor(img_path, shape) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572f66de6a4f4c3783b15abfb52c6db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=76000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6f4c4626a3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split training tensors (images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m76000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save training tensors (images)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-260d1a88f0a5>\u001b[0m in \u001b[0;36mpaths_to_tensor\u001b[0;34m(img_paths, shape)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split training tensors (images)\n",
    "img_shape = (224, 224)\n",
    "train_tensors = paths_to_tensor(train_files_list[:76000], shape = img_shape)\n",
    "\n",
    "# Save training tensors (images)\n",
    "with h5py.File('./efs/Binary/training.hdf5', 'w') as hf:\n",
    "    hf.create_dataset(\"training\",  data=train_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tensors = paths_to_tensor(train_files_list[76000:], shape = img_shape)\n",
    "np.save(open('./efs/Binary/validation.dat', 'wb'), valid_tensors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensors = paths_to_tensor(test_files_list[:], shape = img_shape)\n",
    "np.save(open('./efs/Binary/testing.dat', 'wb'), test_tensors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training labels \n",
    "train_labels = trainL[:76000][:, np.newaxis]\n",
    "valid_labels = trainL[76000:][:, np.newaxis]\n",
    "test_labels = testL[:][:, np.newaxis]\n",
    "# Save training labels \n",
    "np.save(open('./efs/Binary/trainLabels.dat', 'wb'), train_labels, allow_pickle=False)\n",
    "np.save(open('./efs/Binary/validLabels.dat', 'wb'), valid_labels, allow_pickle=False)\n",
    "np.save(open('./efs/Binary/testLabels.dat', 'wb'), test_labels, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with h5py.File('./efs/training.hdf5', 'r') as hf:\n",
    "    train_tensors = hf['./efs/training'][:]\n",
    "valid_tensors = np.load('./efs/validation.dat')\n",
    "test_tensors = np.load('./efs/testing.dat')\n",
    "\n",
    "train_labels = np.load('./efs/trainLabels.dat')\n",
    "valid_labels = np.load('./efs/validLabels.dat')\n",
    "test_labels = np.load('./efs/testLabels.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 7.4MB/s ta 0:00:01\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.23.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 16.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 31.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras) (1.14.5)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/95/274190b39950e1e9eef4b071acefea832ac3e2c19bb4b442fa54f3214d2e/tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (51.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 51.1MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools<=39.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (39.1.0)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.14.5)\n",
      "Collecting tensorboard<1.10.0,>=1.9.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/1f/3da43860db614e294a034e42d4be5c8f7f0d2c75dc1c428c541116d8cdab/tensorboard-1.9.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 21.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.5.2)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/13/b05bbd05d9f0c19e5746f149a285aa81f7c353e231ffecdb237c6e2ad3cc/grpcio-1.13.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.1MB 6.0MB/s eta 0:00:01    13% |████▍                           | 1.2MB 56.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/5d/18feb90462c8edaae71305716c7e8bac479fc9dface63221f808a6b95880/absl-py-0.3.0.tar.gz (84kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 41.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.10.0,>=1.9.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 12.7MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gast, termcolor, absl-py\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/4c/16/ef/e36a23f2432e9220f8845f94e2c3abd39e7d9d1cd458d3159d\n",
      "Successfully built gast termcolor absl-py\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: astor, markdown, tensorboard, gast, termcolor, grpcio, absl-py, tensorflow\n",
      "Successfully installed absl-py-0.3.0 astor-0.7.1 gast-0.2.0 grpcio-1.13.0 markdown-2.6.11 tensorboard-1.9.0 tensorflow-1.9.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
